{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpasMnEk0hnWTYKAFcHCT0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ratnaan23/ds_class/blob/main/ch5_optim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 5 Exercise\n",
        "### 라티나 아스투티 2332036006"
      ],
      "metadata": {
        "id": "mToCbY_lFwF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Redefine the model to be:\n",
        "   ```\n",
        "   w2 * t_u ** 2 + w1 * t_u + b\n",
        "   ```"
      ],
      "metadata": {
        "id": "xWrQgMx4F91V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOvZUIre_VLk"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "torch.set_printoptions(edgeitems=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0,\n",
        "                    3.0, -4.0, 6.0, 13.0, 21.0])\n",
        "t_u = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9,\n",
        "                    33.9, 21.8, 48.4, 60.4, 68.4])\n",
        "t_un = 0.1 * t_u"
      ],
      "metadata": {
        "id": "qRJTVUGC_dkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to change the model here:"
      ],
      "metadata": {
        "id": "8iOcfsc_GP7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(t_u, w1, w2, b):\n",
        "  return w2 * t_u ** 2 + w1 * t_u + b"
      ],
      "metadata": {
        "id": "UsxQ5dAH_kXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(t_p, t_c):\n",
        "  squared_diffs = (t_p - t_c)**2\n",
        "  return squared_diffs.mean()"
      ],
      "metadata": {
        "id": "vmoArTW3_wrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p, t_c)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "  \n",
        "  return params"
      ],
      "metadata": {
        "id": "JVkCss6qAPzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also need to define the initial value for each w1, w2, and b in `params`.\n",
        "\n",
        "In this case, the initial value is:\n",
        "\n",
        "w1 = 1.0\n",
        "\n",
        "w2 = 1.0\n",
        "\n",
        "b = 0.0"
      ],
      "metadata": {
        "id": "-r5vLQgOGZxV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After several trial, the learning-rate value needs to be set to 1e-4 (or lower) to get the loss."
      ],
      "metadata": {
        "id": "zYhrx2amGv2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-4\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = optimizer,\n",
        "    params = params,\n",
        "    t_u = t_un,\n",
        "    t_c = t_c\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTmIQtk9Avua",
        "outputId": "0ebbf75a-53bd-408d-98a2-6416a94ddd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 10.708596\n",
            "Epoch 1000, Loss 8.642083\n",
            "Epoch 1500, Loss 7.171005\n",
            "Epoch 2000, Loss 6.123478\n",
            "Epoch 2500, Loss 5.377227\n",
            "Epoch 3000, Loss 4.845286\n",
            "Epoch 3500, Loss 4.465788\n",
            "Epoch 4000, Loss 4.194724\n",
            "Epoch 4500, Loss 4.000802\n",
            "Epoch 5000, Loss 3.861744\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.8881,  0.5570, -0.8753], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "\n",
        "train_indices, val_indices"
      ],
      "metadata": {
        "id": "oJNkChYxA8dU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d36ed9be-98e5-4679-995e-65ce8da8695c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 5,  4,  3,  1,  8,  2, 10,  7,  9]), tensor([0, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_t_u = t_u[train_indices]\n",
        "train_t_c = t_c[train_indices]\n",
        "\n",
        "val_t_u = t_u[val_indices]\n",
        "val_t_c = t_c[val_indices]\n",
        "\n",
        "train_t_un = 0.1 * train_t_u\n",
        "val_t_un = 0.1 * val_t_u"
      ],
      "metadata": {
        "id": "gUKWqMKzD0G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u,\n",
        "                  train_t_c, val_t_c):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train_t_p = model(train_t_u, *params)\n",
        "        train_loss = loss_fn(train_t_p, train_t_c)\n",
        "                             \n",
        "        val_t_p = model(val_t_u, *params)\n",
        "        val_loss = loss_fn(val_t_p, val_t_c)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch <= 3 or epoch % 500 == 0:\n",
        "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
        "                  f\" Validation loss {val_loss.item():.4f}\")\n",
        "            \n",
        "    return params"
      ],
      "metadata": {
        "id": "jA7K6rk3D3Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-4\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000, \n",
        "    optimizer = optimizer,\n",
        "    params = params,\n",
        "    train_t_u = train_t_un,\n",
        "    val_t_u = val_t_un,\n",
        "    train_t_c = train_t_c,\n",
        "    val_t_c = val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkLe20VZD47o",
        "outputId": "1692fbf2-f5e4-4e1a-8d40-0f4391b0cd59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 782.4936, Validation loss 195.6477\n",
            "Epoch 2, Training loss 411.6089, Validation loss 129.8466\n",
            "Epoch 3, Training loss 219.1735, Validation loss 90.8555\n",
            "Epoch 500, Training loss 9.7347, Validation loss 18.2875\n",
            "Epoch 1000, Training loss 8.2693, Validation loss 14.7293\n",
            "Epoch 1500, Training loss 7.1645, Validation loss 12.0038\n",
            "Epoch 2000, Training loss 6.3311, Validation loss 9.9114\n",
            "Epoch 2500, Training loss 5.7021, Validation loss 8.3013\n",
            "Epoch 3000, Training loss 5.2271, Validation loss 7.0589\n",
            "Epoch 3500, Training loss 4.8681, Validation loss 6.0975\n",
            "Epoch 4000, Training loss 4.5963, Validation loss 5.3511\n",
            "Epoch 4500, Training loss 4.3902, Validation loss 4.7697\n",
            "Epoch 5000, Training loss 4.2337, Validation loss 4.3151\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.7012,  0.5288, -0.8004], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-1\n",
        "optimizer = optim.Adam([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000, \n",
        "    optimizer = optimizer,\n",
        "    params = params,\n",
        "    train_t_u = train_t_u,\n",
        "    val_t_u = val_t_u,\n",
        "    train_t_c = train_t_c,\n",
        "    val_t_c = val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSYuu7dFEhwG",
        "outputId": "0a8a2e69-62f4-4551-c857-b1d43b57055e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 13966250.0000, Validation loss 1553974.0000\n",
            "Epoch 2, Training loss 11302069.0000, Validation loss 1258117.5000\n",
            "Epoch 3, Training loss 8928869.0000, Validation loss 994507.0625\n",
            "Epoch 500, Training loss 4.9185, Validation loss 6.5057\n",
            "Epoch 1000, Training loss 4.1196, Validation loss 4.2992\n",
            "Epoch 1500, Training loss 3.7427, Validation loss 3.1047\n",
            "Epoch 2000, Training loss 3.6265, Validation loss 2.6625\n",
            "Epoch 2500, Training loss 3.5805, Validation loss 2.5331\n",
            "Epoch 3000, Training loss 3.5363, Validation loss 2.4998\n",
            "Epoch 3500, Training loss 3.4814, Validation loss 2.4896\n",
            "Epoch 4000, Training loss 3.4132, Validation loss 2.4826\n",
            "Epoch 4500, Training loss 3.3294, Validation loss 2.4757\n",
            "Epoch 5000, Training loss 3.2283, Validation loss 2.4691\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0602,  0.0056, -2.6406], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting loss is higher using the new model compared to the previous one. The validation loss also reached a lower point than the training loss in the earlier stage of epoch."
      ],
      "metadata": {
        "id": "-5Bf9xC-HygQ"
      }
    }
  ]
}
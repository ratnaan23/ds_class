{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpasMnEk0hnWTYKAFcHCT0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ratnaan23/ds_class/blob/main/ch5_optim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 5 Exercise\n",
        "### 라티나 아스투티 2332036006"
      ],
      "metadata": {
        "id": "mToCbY_lFwF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Redefine the model to be:\n",
        "   ```\n",
        "   w2 * t_u ** 2 + w1 * t_u + b\n",
        "   ```"
      ],
      "metadata": {
        "id": "xWrQgMx4F91V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOvZUIre_VLk"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "torch.set_printoptions(edgeitems=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0,\n",
        "                    3.0, -4.0, 6.0, 13.0, 21.0])\n",
        "t_u = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9,\n",
        "                    33.9, 21.8, 48.4, 60.4, 68.4])\n",
        "t_un = 0.1 * t_u"
      ],
      "metadata": {
        "id": "qRJTVUGC_dkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to change the model here:"
      ],
      "metadata": {
        "id": "8iOcfsc_GP7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(t_u, w1, w2, b):\n",
        "  return w2 * t_u ** 2 + w1 * t_u + b"
      ],
      "metadata": {
        "id": "UsxQ5dAH_kXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(t_p, t_c):\n",
        "  squared_diffs = (t_p - t_c)**2\n",
        "  return squared_diffs.mean()"
      ],
      "metadata": {
        "id": "vmoArTW3_wrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p, t_c)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "  \n",
        "  return params"
      ],
      "metadata": {
        "id": "JVkCss6qAPzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also need to define the initial value for each w1, w2, and b in `params`.\n",
        "\n",
        "In this case, the initial value is:\n",
        "\n",
        "w1 = 1.0\n",
        "\n",
        "w2 = 1.0\n",
        "\n",
        "b = 0.0"
      ],
      "metadata": {
        "id": "-r5vLQgOGZxV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After several trial, the learning-rate value needs to be set to 1e-4 (or lower) to get the loss."
      ],
      "metadata": {
        "id": "zYhrx2amGv2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-4\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = optimizer,\n",
        "    params = params,\n",
        "    t_u = t_un,\n",
        "    t_c = t_c\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTmIQtk9Avua",
        "outputId": "14654de9-0037-4a9e-9322-7009872da6c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 10.708596\n",
            "Epoch 1000, Loss 8.642083\n",
            "Epoch 1500, Loss 7.171005\n",
            "Epoch 2000, Loss 6.123478\n",
            "Epoch 2500, Loss 5.377227\n",
            "Epoch 3000, Loss 4.845286\n",
            "Epoch 3500, Loss 4.465788\n",
            "Epoch 4000, Loss 4.194724\n",
            "Epoch 4500, Loss 4.000802\n",
            "Epoch 5000, Loss 3.861744\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.8881,  0.5570, -0.8753], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "\n",
        "train_indices, val_indices"
      ],
      "metadata": {
        "id": "oJNkChYxA8dU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce39ea7f-a39f-4308-fd3b-679980e821d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 9,  4, 10,  8,  0,  3,  7,  5,  1]), tensor([6, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_t_u = t_u[train_indices]\n",
        "train_t_c = t_c[train_indices]\n",
        "\n",
        "val_t_u = t_u[val_indices]\n",
        "val_t_c = t_c[val_indices]\n",
        "\n",
        "train_t_un = 0.1 * train_t_u\n",
        "val_t_un = 0.1 * val_t_u"
      ],
      "metadata": {
        "id": "gUKWqMKzD0G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u,\n",
        "                  train_t_c, val_t_c):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train_t_p = model(train_t_u, *params)\n",
        "        train_loss = loss_fn(train_t_p, train_t_c)\n",
        "                             \n",
        "        val_t_p = model(val_t_u, *params)\n",
        "        val_loss = loss_fn(val_t_p, val_t_c)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch <= 3 or epoch % 500 == 0:\n",
        "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
        "                  f\" Validation loss {val_loss.item():.4f}\")\n",
        "            \n",
        "    return params"
      ],
      "metadata": {
        "id": "jA7K6rk3D3Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-4\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000, \n",
        "    optimizer = optimizer,\n",
        "    params = params,\n",
        "    train_t_u = train_t_un,\n",
        "    val_t_u = val_t_un,\n",
        "    train_t_c = train_t_c,\n",
        "    val_t_c = val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkLe20VZD47o",
        "outputId": "82b78cb1-e3f4-4bf9-974f-302f74d6f4a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 742.5377, Validation loss 375.4495\n",
            "Epoch 2, Training loss 416.5768, Validation loss 208.6635\n",
            "Epoch 3, Training loss 236.7594, Validation loss 116.8267\n",
            "Epoch 500, Training loss 12.0186, Validation loss 3.4329\n",
            "Epoch 1000, Training loss 9.5043, Validation loss 2.5997\n",
            "Epoch 1500, Training loss 7.7160, Validation loss 2.2386\n",
            "Epoch 2000, Training loss 6.4436, Validation loss 2.1767\n",
            "Epoch 2500, Training loss 5.5379, Validation loss 2.2969\n",
            "Epoch 3000, Training loss 4.8927, Validation loss 2.5207\n",
            "Epoch 3500, Training loss 4.4327, Validation loss 2.7964\n",
            "Epoch 4000, Training loss 4.1043, Validation loss 3.0907\n",
            "Epoch 4500, Training loss 3.8694, Validation loss 3.3826\n",
            "Epoch 5000, Training loss 3.7010, Validation loss 3.6600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.0695,  0.5798, -0.9587], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-1\n",
        "optimizer = optim.Adam([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000, \n",
        "    optimizer = optimizer,\n",
        "    params = params,\n",
        "    train_t_u = train_t_u,\n",
        "    val_t_u = val_t_u,\n",
        "    train_t_c = train_t_c,\n",
        "    val_t_c = val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSYuu7dFEhwG",
        "outputId": "c262ea6b-5bcd-4d88-faa6-425ae6a666bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 12849290.0000, Validation loss 6580289.0000\n",
            "Epoch 2, Training loss 10398391.0000, Validation loss 5324670.5000\n",
            "Epoch 3, Training loss 8215151.0000, Validation loss 4206235.0000\n",
            "Epoch 500, Training loss 5.3014, Validation loss 2.2282\n",
            "Epoch 1000, Training loss 3.7736, Validation loss 3.2903\n",
            "Epoch 1500, Training loss 3.2679, Validation loss 4.5707\n",
            "Epoch 2000, Training loss 3.1677, Validation loss 5.2880\n",
            "Epoch 2500, Training loss 3.1291, Validation loss 5.5075\n",
            "Epoch 3000, Training loss 3.0860, Validation loss 5.5392\n",
            "Epoch 3500, Training loss 3.0320, Validation loss 5.5329\n",
            "Epoch 4000, Training loss 2.9649, Validation loss 5.5209\n",
            "Epoch 4500, Training loss 2.8829, Validation loss 5.5066\n",
            "Epoch 5000, Training loss 2.7845, Validation loss 5.4902\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0877,  0.0059, -2.7560], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting loss is higher using the new model compared to the previous one. The validation loss also reached a lower point than the training loss in the earlier stage of epoch."
      ],
      "metadata": {
        "id": "-5Bf9xC-HygQ"
      }
    }
  ]
}